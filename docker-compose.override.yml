services:

# ---------------- MLflow ----------------

  mlflow:
    image: python:3.11-slim
    #platform: linux/arm64
    command: >
      bash -c "pip install mlflow==2.9.2 psycopg2-binary boto3 && 
               export MLFLOW_S3_ENDPOINT_URL=http://minio:9000 &&
               mlflow server --host 0.0.0.0 --port 5001 
               --backend-store-uri postgresql://mlflow:mlflow@mlflow-db:5432/mlflow 
               --default-artifact-root s3://mlflow-artifacts/ 
               --serve-artifacts"
    ports:
      - "5001:5001"
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_DEFAULT_REGION=us-east-1
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_S3_FORCE_PATH_STYLE=true
    depends_on:
      - mlflow-db
      - minio 
    networks:
      - airflow
      - default
    restart: unless-stopped


  mlflow-db:
    image: postgres:16-alpine
    #platform: linux/arm64
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
    volumes:
      - mlflow-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD', 'pg_isready', '-U', 'mlflow']
      interval: 5s
      retries: 5
      start_period: 10s
    networks:
      - airflow
      - default
    restart: unless-stopped


  minio:
    image: minio/minio:latest
    #platform: linux/arm64
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:9000/minio/health/live']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - airflow
      - default
    restart: unless-stopped


  minio-mc:
    image: minio/mc:latest
    #platform: linux/arm64
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set localminio http://minio:9000 minioadmin minioadmin &&
      mc mb localminio/mlflow-artifacts || true &&
      true
      "
    networks:
      - airflow
      - default


  #Prediction API Service
  prediction-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8000:8000"
    environment:
      - MODEL_DIR=/app/models
      - MLFLOW_TRACKING_URI=http://mlflow:5001
      - DATABASE_URL=postgresql://monitoring:monitoring@monitoring-db:5432/monitoring
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./models:/app/models:ro
      - ./configs:/app/configs:ro
    depends_on:
      - mlflow
      #- redis
      #- monitoring-db
    networks:
      - airflow
      - default
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3


  # #Model Monitoring Service
  # monitoring:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.monitoring
  #   environment:
  #     - DATABASE_URL=postgresql://monitoring:monitoring@monitoring-db:5432/monitoring
  #     - MLFLOW_TRACKING_URI=http://mlflow:5001
  #     - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-}
  #     - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST:-smtp.gmail.com}
  #     - EMAIL_SMTP_PORT=${EMAIL_SMTP_PORT:-587}
  #   volumes:
  #     - ./monitoring_data:/app/data
  #     - ./configs:/app/configs:ro
  #   depends_on:
  #     - monitoring-db
  #     - mlflow
  #   networks:
  #     - airflow
  #     - default
  #   restart: unless-stopped


  # monitoring-db:
  #   image: postgres:16-alpine
  #   environment:
  #     POSTGRES_USER: monitoring
  #     POSTGRES_PASSWORD: monitoring
  #     POSTGRES_DB: monitoring
  #   volumes:
  #     - monitoring-db-volume:/var/lib/postgresql/data
  #   healthcheck:
  #     test: ['CMD', 'pg_isready', '-U', 'monitoring']
  #     interval: 5s
  #     retries: 5
  #     start_period: 10s
  #   networks:
  #     - airflow
  #     - default
  #   restart: unless-stopped


  # # ---------------- Redis ----------------
  # redis:
  #   image: redis:7-alpine
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis-data:/data
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 5s
  #     timeout: 3s
  #     retries: 5
  #   networks:
  #     - airflow
  #     - default
  #   restart: unless-stopped


  # # Prometheus for metrics collection
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./backend/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #     - ./backend/monitoring/prometheus/rules.yml:/etc/prometheus/rules.yml:ro
  #     - prometheus-data:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.enable-lifecycle'
  #   networks:
  #     - airflow
  #   restart: unless-stopped


  # alertmanager:
  #   image: prom/alertmanager:latest
  #   container_name: alertmanager
  #   volumes:
  #     - ./backend/monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
  #   command:
  #     - "--config.file=/etc/alertmanager/alertmanager.yml"
  #   ports:
  #     - "9093:9093"
  #   networks:
  #     - airflow
  #     - default


  # node-exporter:
  #   image: prom/node-exporter:latest
  #   container_name: node-exporter
  #   restart: unless-stopped
  #   pid: "host"
  #   network_mode: "host"   # optional: gives host metrics; remove if running in swarm/other envs
  #   command:
  #     - '--path.rootfs=/host'
  #   volumes:
  #     - /proc:/host/proc:ro
  #     - /sys:/host/sys:ro
  #     - /:/host:ro


  # # Grafana for monitoring dashboards
  # grafana:
  #   image: grafana/grafana:latest
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #     - GF_USERS_ALLOW_SIGN_UP=false
  #   volumes:
  #     - grafana-data:/var/lib/grafana
  #     - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
  #     - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
  #   depends_on:
  #     - prometheus
  #   networks:
  #     - airflow
  #     - default
  #   restart: unless-stopped


  # # Nginx reverse proxy and load balancer
  # nginx:
  #   image: nginx:alpine
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./ssl:/etc/ssl:ro
  #   depends_on:
  #     - prediction-api
  #     - grafana
  #   networks:
  #     - airflow
  #     - default
  #   restart: unless-stopped

    
   # Streamlit UI for model inference
  streamlit-ui:
    image: python:3.11-slim
    working_dir: /app
    command: >
      bash -c "
      apt-get update && apt-get install -y libgomp1 build-essential cmake &&
      pip install --no-cache-dir streamlit==1.29.0 pandas==2.1.4 numpy==1.24.3 scikit-learn==1.3.2 matplotlib==3.8.2 seaborn==0.13.0 plotly==5.18.0 mlflow==2.9.2 boto3==1.34.14 lightgbm==4.2.0 catboost==1.2.2 xgboost==2.0.3 &&
      chmod +x /app/entrypoint.sh &&
      /app/entrypoint.sh
      "
    ports:
      - '8501:8501'
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5001
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_DEFAULT_REGION=us-east-1
    volumes:
      - ./backend/ui:/app             
      - ./include:/usr/local/airflow/include:ro
    depends_on:
      - mlflow
      - minio
    restart: unless-stopped


networks:
  airflow:
    external: true
    name: sales-ai_e0abfd_airflow
  default:
    name: sales-ai_e0abfd_default

volumes:
  mlflow-db-volume:
 # monitoring-db-volume:
  minio-data:
  redis-data:
  #prometheus-data:
  #grafana-data:
