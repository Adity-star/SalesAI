{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Tuple, Any, Union\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a06cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\OneDrive\\Desktop\\SalesAI\\backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\salesenv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c6d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:19:53,841 ] root - \u001b[32mINFO\u001b[0m - \u001b[32mLogger is configured and ready.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.utils.config_loader import load_config\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BacktestConfig:\n",
    "    \"\"\"Configuration for backtesting parameters.\"\"\"\n",
    "    # Time periods\n",
    "    train_start_date: str = \"2013-01-01\"\n",
    "    validation_start_date: str = \"2013-02-01\" \n",
    "    test_start_date: str = \"2015-06-01\"\n",
    "    test_end_date: str = \"2015-09-01\"\n",
    "    \n",
    "    # Rolling window settings\n",
    "    initial_train_days: int = 90  # 2 years initial training\n",
    "    step_size_days: int = 20       # Retrain monthly\n",
    "    min_train_days: int = 30      # Minimum training period\n",
    "    \n",
    "    # Forecast horizons\n",
    "    horizons: List[int] = field(default_factory=lambda: [7, 14, 28])\n",
    "    \n",
    "    # Model settings\n",
    "    models_to_evaluate: List[str] = field(default_factory=lambda: ['lightgbm'])\n",
    "    hyperparameter_tuning: bool = False\n",
    "    \n",
    "    # Evaluation settings\n",
    "    stratify_by: List[str] = field(default_factory=lambda: ['cat_id', 'dept_id', 'store_id', 'state_id'])\n",
    "    save_predictions: bool = True\n",
    "    memory_efficient: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7231afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"Container for evaluation metrics.\"\"\"\n",
    "    rmse: float = 0.0\n",
    "    mae: float = 0.0 \n",
    "    mase: float = 0.0\n",
    "    smape: float = 0.0\n",
    "    mape: float = 0.0\n",
    "    mean_prediction: float = 0.0\n",
    "    mean_actual: float = 0.0\n",
    "    samples: int = 0\n",
    "    zero_predictions_pct: float = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d850597",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BacktestResults:\n",
    "    \"\"\"Container for backtest results.\"\"\"\n",
    "    model_name: str\n",
    "    horizon: int\n",
    "    metrics: EvaluationMetrics\n",
    "    predictions: Optional[pd.DataFrame] = None\n",
    "    feature_importance: Optional[pd.DataFrame] = None\n",
    "    training_time: float = 0.0\n",
    "    prediction_time: float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63d287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MetricsCalculator:\n",
    "    \"\"\"Calculate M5-specific forecasting metrics.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"Root Mean Square Error.\"\"\"\n",
    "        result = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        logger.debug(f\"üî¢ RMSE calculated: {result:.4f}\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"Mean Absolute Error.\"\"\"\n",
    "        result = mean_absolute_error(y_true, y_pred)\n",
    "        logger.debug(f\"‚úÇÔ∏è MAE calculated: {result:.4f}\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def mase(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray, \n",
    "             seasonal_period: int = 7) -> float:\n",
    "        \"\"\"Mean Absolute Scaled Error - critical for M5 competition.\"\"\"\n",
    "        if len(y_train) < seasonal_period:\n",
    "            logger.warning(\"‚ö†Ô∏è MASE: y_train length less than seasonal_period, returning NaN\")\n",
    "            return np.nan\n",
    "        \n",
    "        naive_errors = np.abs(y_train[seasonal_period:] - y_train[:-seasonal_period])\n",
    "        scale = np.mean(naive_errors)\n",
    "        \n",
    "        if scale == 0 or np.isnan(scale):\n",
    "            logger.warning(\"‚ö†Ô∏è MASE: scale is zero or NaN, returning 0.0\")\n",
    "            return 0.0\n",
    "        \n",
    "        result = np.mean(np.abs(y_true - y_pred)) / scale\n",
    "        logger.debug(f\"üìè MASE calculated: {result:.4f}\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def smape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "        numerator = np.abs(y_true - y_pred)\n",
    "        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "        \n",
    "        mask = denominator != 0\n",
    "        if not np.any(mask):\n",
    "            logger.warning(\"‚ö†Ô∏è SMAPE: denominator zero for all samples, returning 0.0\")\n",
    "            return 0.0\n",
    "        \n",
    "        result = np.mean(numerator[mask] / denominator[mask]) * 100\n",
    "        logger.debug(f\"üìâ SMAPE calculated: {result:.4f}%\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"Mean Absolute Percentage Error.\"\"\"\n",
    "        mask = y_true != 0\n",
    "        if not np.any(mask):\n",
    "            logger.warning(\"‚ö†Ô∏è MAPE: y_true contains all zeros, returning infinity\")\n",
    "            return np.inf\n",
    "        \n",
    "        result = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "        logger.debug(f\"üìä MAPE calculated: {result:.4f}%\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(y_true: np.ndarray, y_pred: np.ndarray, \n",
    "                              y_train: np.ndarray):\n",
    "        \"\"\"Calculate all metrics at once.\"\"\"\n",
    "        logger.info(\"üöÄ Calculating all evaluation metrics...\")\n",
    "        calc = MetricsCalculator()\n",
    "        \n",
    "        y_pred_clipped = np.maximum(y_pred, 0)  # Ensure no negative predictions\n",
    "        \n",
    "        metrics = dict(\n",
    "            rmse=calc.rmse(y_true, y_pred_clipped),\n",
    "            mae=calc.mae(y_true, y_pred_clipped),\n",
    "            mase=calc.mase(y_true, y_pred_clipped, y_train),\n",
    "            smape=calc.smape(y_true, y_pred_clipped),\n",
    "            mape=calc.mape(y_true, y_pred_clipped),\n",
    "            mean_prediction=np.mean(y_pred_clipped),\n",
    "            mean_actual=np.mean(y_true),\n",
    "            samples=len(y_true),\n",
    "            zero_predictions_pct=np.mean(y_pred_clipped == 0) * 100\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"‚úÖ Metrics calculated: RMSE={metrics['rmse']:.4f}, MAE={metrics['mae']:.4f}, MASE={metrics['mase']:.4f}, SMAPE={metrics['smape']:.2f}%, MAPE={metrics['mape']:.2f}%\")\n",
    "        logger.debug(f\"Mean prediction: {metrics['mean_prediction']:.4f}, Mean actual: {metrics['mean_actual']:.4f}, Zero predictions: {metrics['zero_predictions_pct']:.2f}%\")\n",
    "        \n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a0851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(ABC):\n",
    "    \"\"\"Abstract base class for M5 models.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, **kwargs):\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        self.fitted = False\n",
    "        self.feature_importance_ = None\n",
    "        self.training_time = 0.0\n",
    "        self.prediction_time = 0.0\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
    "        \"\"\"Fit model to training data.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_feature_importance(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Get feature importance if available.\"\"\"\n",
    "        return self.feature_importance_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1df8cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LightGBMModel(BaseModel):\n",
    "    \"\"\"LightGBM model optimized for M5 dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"LightGBM\", **lgb_params):\n",
    "        super().__init__(name)\n",
    "        self.lgb_params = {\n",
    "            'objective': 'poisson',  # Better for count data\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 127,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42,\n",
    "            'num_threads': 4\n",
    "        }\n",
    "        self.lgb_params.update(lgb_params)\n",
    "        self.fitted = False\n",
    "        self.feature_importance_ = None\n",
    "        self.training_time = None\n",
    "        self.prediction_time = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series,  X_valid: pd.DataFrame = None, y_valid: pd.Series = None, **kwargs):\n",
    "        \"\"\"Fit LightGBM model with early stopping.\"\"\"\n",
    "        logger.info(\"üöÄ Starting LightGBM training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        feature_cols = [col for col in X.columns if col not in ['date', 'store_id', 'item_id']]\n",
    "        X_train = X[feature_cols].copy()\n",
    "\n",
    "        # Identify categorical features\n",
    "        categorical_features = []\n",
    "        for col in X_train.columns:\n",
    "            if X_train[col].dtype.name == 'category':\n",
    "                categorical_features.append(col)\n",
    "                X_train[col] = X_train[col].astype('category')\n",
    "\n",
    "        train_data = lgb.Dataset(\n",
    "            X_train,\n",
    "            label=y,\n",
    "            categorical_feature=categorical_features,\n",
    "            free_raw_data=False\n",
    "        )\n",
    "\n",
    "        valid_sets = None\n",
    "        valid_names = None\n",
    "\n",
    "        if X_valid is not None and y_valid is not None:\n",
    "            X_val = X_valid[feature_cols].copy()\n",
    "            for col in X_val.columns:\n",
    "                if X_val[col].dtype.name == 'category':\n",
    "                    X_val[col] = X_val[col].astype('category')\n",
    "            \n",
    "            valid_data = lgb.Dataset(X_val, label=y_valid, categorical_feature=categorical_features, free_raw_data=False)\n",
    "            valid_sets = [train_data, valid_data]\n",
    "            valid_names = ['train', 'valid']\n",
    "        else:\n",
    "            valid_sets = [train_data]\n",
    "            valid_names = ['train']\n",
    "\n",
    "        num_boost_round = kwargs.get('num_boost_round', 1000)\n",
    "        early_stopping_rounds = kwargs.get('early_stopping_rounds', 100)\n",
    "\n",
    "         \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.model = lgb.train(\n",
    "                self.lgb_params,\n",
    "                train_data,\n",
    "                num_boost_round=num_boost_round,\n",
    "                valid_sets=valid_sets,\n",
    "                valid_names=valid_names,\n",
    "                callbacks=[\n",
    "                lgb.early_stopping(early_stopping_rounds),\n",
    "                lgb.log_evaluation(0)\n",
    "            ])\n",
    "        \n",
    "\n",
    "        if self.model:\n",
    "            self.feature_importance_ = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': self.model.feature_importance(importance_type='gain')\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            logger.info(f\"üìä Feature importance computed for {len(self.feature_importance_)} features\")\n",
    "\n",
    "        self.fitted = True\n",
    "        self.training_time = time.time() - start_time\n",
    "        logger.info(f\"‚úÖ Training completed in {self.training_time:.2f} seconds\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Make predictions with LightGBM.\"\"\"\n",
    "        if not self.fitted:\n",
    "            logger.error(\"‚ùå Prediction attempted before model was fitted\")\n",
    "            raise ValueError(\"Model must be fitted before predicting\")\n",
    "\n",
    "        logger.info(\"‚ö° Starting prediction...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        feature_cols = [col for col in X.columns if col not in ['date', 'store_id', 'item_id']]\n",
    "        X_pred = X[feature_cols].copy()\n",
    "\n",
    "        for col in X_pred.columns:\n",
    "            if X_pred[col].dtype.name == 'category':\n",
    "                X_pred[col] = X_pred[col].astype('category')\n",
    "\n",
    "        predictions = self.model.predict(X_pred)\n",
    "        predictions = np.maximum(predictions, 0)  # no negative forecasts\n",
    "\n",
    "        self.prediction_time = time.time() - start_time\n",
    "        logger.info(f\"‚úÖ Prediction completed in {self.prediction_time:.2f} seconds\")\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3bcd6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestEngine:\n",
    "    \"\"\"M5-specific backtesting engine with rolling-origin validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: BacktestConfig, output_dir: str = \"backtest_results\"):\n",
    "        self.config = config\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        (self.output_dir / \"predictions\").mkdir(exist_ok=True)\n",
    "        (self.output_dir / \"models\").mkdir(exist_ok=True)\n",
    "        (self.output_dir / \"reports\").mkdir(exist_ok=True)\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        logger.info(f\"Initialized M5 backtesting engine\")\n",
    "        logger.info(f\"Horizons: {self.config.horizons}\")\n",
    "        logger.info(f\"Models: {self.config.models_to_evaluate}\")\n",
    "    \n",
    "    def prepare_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare data for backtesting.\"\"\"\n",
    "        logger.info(\"üõ†Ô∏è Preparing data for backtesting...\")\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_cols = ['date', 'store_id', 'item_id', 'sales']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Ensure date is datetime\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Sort data\n",
    "        df = df.sort_values(['store_id', 'item_id', 'date']).reset_index(drop=True)\n",
    "        \n",
    "        # Filter date range\n",
    "        start_date = pd.to_datetime(self.config.train_start_date)\n",
    "        end_date = pd.to_datetime(self.config.test_end_date)\n",
    "        df = df[(df['date'] >= start_date) & (df['date'] <= end_date)].copy()\n",
    "        \n",
    "        logger.info(f\"‚úÖ Prepared data: {df.shape[0]} rows\")\n",
    "        logger.info(f\"üìÖ Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "        logger.info(f\"üß© Unique series count: {df.groupby(['store_id', 'item_id'],observed=False).ngroups}\")\n",
    "        return df\n",
    "    \n",
    "    def get_time_splits(self) -> List[Tuple[str, str, str]]:\n",
    "        \"\"\"Generate rolling-origin time splits.\"\"\"\n",
    "        logger.info(\"üîÑ Generating rolling-origin time splits...\")\n",
    "        \n",
    "        validation_start = pd.to_datetime(self.config.validation_start_date)\n",
    "        test_start = pd.to_datetime(self.config.test_start_date)\n",
    "        test_end = pd.to_datetime(self.config.test_end_date)\n",
    "        \n",
    "        splits = []\n",
    "        current_test_start = test_start\n",
    "        \n",
    "        while current_test_start <= test_end:\n",
    "            # Calculate training end (before validation period)\n",
    "            train_end = current_test_start - timedelta(days=1)\n",
    "            train_start = train_end - timedelta(days=self.config.initial_train_days)\n",
    "            \n",
    "            # Ensure minimum training period\n",
    "            if (train_end - train_start).days >= self.config.min_train_days:\n",
    "                splits.append((\n",
    "                    train_start.strftime('%Y-%m-%d'),\n",
    "                    train_end.strftime('%Y-%m-%d'),\n",
    "                    current_test_start.strftime('%Y-%m-%d')\n",
    "                ))\n",
    "            \n",
    "            # Move to next test period\n",
    "            current_test_start += timedelta(days=self.config.step_size_days)\n",
    "        \n",
    "        logger.info(f\"üìä Generated {len(splits)} time splits\")\n",
    "        return splits\n",
    "    \n",
    "    def create_model(self, model_name: str) -> BaseModel:\n",
    "        \"\"\"Create model instance.\"\"\"\n",
    "        if model_name == 'lightgbm':\n",
    "            return LightGBMModel()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    def evaluate_split(self, df: pd.DataFrame, train_start: str, train_end: str, test_start: str) -> List[BacktestResults]:\n",
    "        from types import SimpleNamespace\n",
    "\n",
    "        logger.info(f\"Evaluating split: train {train_start} to {train_end}, test from {test_start}\")\n",
    "        \n",
    "        train_mask = (df['date'] >= train_start) & (df['date'] <= train_end)\n",
    "        train_data = df[train_mask].copy()\n",
    "        \n",
    "        if len(train_data) == 0:\n",
    "            logger.warning(\"Empty training data\")\n",
    "            return []\n",
    "        \n",
    "        split_results = []\n",
    "        \n",
    "        for model_name in self.config.models_to_evaluate:\n",
    "            logger.info(f\"Training {model_name}...\")\n",
    "            \n",
    "            try:\n",
    "                model = self.create_model(model_name)\n",
    "                \n",
    "                feature_cols = [col for col in train_data.columns if col not in ['sales', 'd'] and not col.startswith('id')]\n",
    "                X_train = train_data[['date', 'store_id', 'item_id'] + feature_cols]\n",
    "                y_train = train_data['sales']\n",
    "                \n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                for horizon in self.config.horizons:\n",
    "                    test_end_date = pd.to_datetime(test_start) + timedelta(days=horizon)\n",
    "                    test_mask = (df['date'] >= test_start) & (df['date'] < test_end_date)\n",
    "                    test_data = df[test_mask].copy()\n",
    "                    \n",
    "                    if len(test_data) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    X_test = test_data[['date', 'store_id', 'item_id'] + feature_cols]\n",
    "                    y_test = test_data['sales']\n",
    "                    \n",
    "                    predictions = model.predict(X_test)\n",
    "                    \n",
    "                    # Wrap the dict into an object with attribute access\n",
    "                    metrics_dict = MetricsCalculator.calculate_all_metrics(y_test.values, predictions, y_train.values)\n",
    "                    metrics = SimpleNamespace(**metrics_dict)\n",
    "                    \n",
    "                    result = BacktestResults(\n",
    "                        model_name=model_name,\n",
    "                        horizon=horizon,\n",
    "                        metrics=metrics,\n",
    "                        training_time=model.training_time,\n",
    "                        prediction_time=model.prediction_time\n",
    "                    )\n",
    "                    \n",
    "                    if self.config.save_predictions:\n",
    "                        pred_df = test_data[['date', 'store_id', 'item_id', 'sales']].copy()\n",
    "                        pred_df['prediction'] = predictions\n",
    "                        pred_df['model'] = model_name\n",
    "                        pred_df['horizon'] = horizon\n",
    "                        result.predictions = pred_df\n",
    "                    \n",
    "                    if hasattr(model, 'get_feature_importance'):\n",
    "                        result.feature_importance = model.get_feature_importance()\n",
    "                    \n",
    "                    split_results.append(result)\n",
    "                    \n",
    "                    logger.info(f\"{model_name} H{horizon}: RMSE={metrics.rmse:.3f}, \"\n",
    "                                f\"MAE={metrics.mae:.3f}, MASE={metrics.mase:.3f}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to evaluate {model_name}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            del model\n",
    "            gc.collect()\n",
    "        \n",
    "        return split_results\n",
    "\n",
    "     \n",
    "    \n",
    "    def run_backtest(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Run complete backtesting procedure.\"\"\"\n",
    "        logger.info(\"üöÄ Starting backtesting procedure...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Prepare data\n",
    "        df_prepared = self.prepare_data(df)\n",
    "        \n",
    "        # Get time splits\n",
    "        time_splits = self.get_time_splits()\n",
    "        \n",
    "        # Run evaluation on each split\n",
    "        all_results = []\n",
    "        \n",
    "        for i, (train_start, train_end, test_start) in enumerate(time_splits):\n",
    "            logger.info(f\"Processing split {i+1}/{len(time_splits)}\")\n",
    "            \n",
    "            split_results = self.evaluate_split(df_prepared, train_start, train_end, test_start)\n",
    "            all_results.extend(split_results)\n",
    "            \n",
    "            # Save intermediate results\n",
    "            if i % 2 == 0:  # Save every 2 splits\n",
    "                self._save_intermediate_results(all_results)\n",
    "                gc.collect()\n",
    "        \n",
    "        # Aggregate and save final results\n",
    "        results_df = self._aggregate_results(all_results)\n",
    "        self._save_final_results(results_df, all_results)\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        logger.info(f\"‚úÖ Backtesting completed in {duration / 60:.1f} minutes\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def _aggregate_results(self, results: List[BacktestResults]) -> pd.DataFrame:\n",
    "        \"\"\"Aggregate results across splits.\"\"\"\n",
    "        logger.info(\"üìä Aggregating backtest results...\")\n",
    "        \n",
    "        summary_data = []\n",
    "        \n",
    "        # Group by model and horizon\n",
    "        for model_name in self.config.models_to_evaluate:\n",
    "            for horizon in self.config.horizons:\n",
    "                # Filter results for this model-horizon combination\n",
    "                model_results = [r for r in results \n",
    "                               if r.model_name == model_name and r.horizon == horizon]\n",
    "                \n",
    "                if not model_results:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate average metrics\n",
    "                avg_metrics = {\n",
    "                    'rmse': np.mean([r.metrics.rmse for r in model_results]),\n",
    "                    'mae': np.mean([r.metrics.mae for r in model_results]),\n",
    "                    'mase': np.mean([r.metrics.mase for r in model_results if not np.isnan(r.metrics.mase)]),\n",
    "                    'smape': np.mean([r.metrics.smape for r in model_results]),\n",
    "                    'training_time': np.mean([r.training_time for r in model_results]),\n",
    "                    'prediction_time': np.mean([r.prediction_time for r in model_results]),\n",
    "                    'n_splits': len(model_results)\n",
    "                }\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'model': model_name,\n",
    "                    'horizon': horizon,\n",
    "                    **avg_metrics\n",
    "                })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        return summary_df\n",
    "    \n",
    "    def _save_intermediate_results(self, results: List[BacktestResults]):\n",
    "        \"\"\"Save intermediate results to prevent data loss.\"\"\"\n",
    "        logger.info(\"üíæ Saving intermediate results to prevent data loss...\")\n",
    "\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        temp_path = self.output_dir / f\"temp_results_{timestamp}.json\"\n",
    "        \n",
    "        # Convert results to JSON-serializable format\n",
    "        results_data = []\n",
    "        for result in results:\n",
    "            result_dict = {\n",
    "                'model_name': result.model_name,\n",
    "                'horizon': result.horizon,\n",
    "                'metrics': vars(result.metrics),\n",
    "                'training_time': result.training_time,\n",
    "                'prediction_time': result.prediction_time\n",
    "            }\n",
    "            results_data.append(result_dict)\n",
    "        \n",
    "        with open(temp_path, 'w') as f:\n",
    "            json.dump(results_data, f)\n",
    "    \n",
    "    def _save_final_results(self, summary_df: pd.DataFrame, all_results: List[BacktestResults]):\n",
    "        \"\"\"Save final backtest results.\"\"\"\n",
    "\n",
    "        logger.info(\"üíæ Saving final backtest results and generating report...\")\n",
    "\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Save summary table\n",
    "        summary_path = self.output_dir / f\"backtest_summary_{timestamp}.csv\"\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        \n",
    "        # Save detailed results\n",
    "        detailed_path = self.output_dir / f\"backtest_detailed_{timestamp}.json\"\n",
    "        detailed_results = []\n",
    "\n",
    "        def convert_np_types(obj):\n",
    "            # Recursively convert numpy types to native Python types\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: convert_np_types(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, (np.float32, np.float64)):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, (np.int32, np.int64)):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_np_types(i) for i in obj]\n",
    "            else:\n",
    "                return obj\n",
    "        \n",
    "        for result in all_results:\n",
    "            result_dict = {\n",
    "                'model_name': result.model_name,\n",
    "                'horizon': result.horizon,\n",
    "                'metrics': convert_np_types(vars(result.metrics)),\n",
    "                'training_time': float(result.training_time),\n",
    "                'prediction_time': float(result.prediction_time)\n",
    "            }\n",
    "            detailed_results.append(result_dict)\n",
    "        \n",
    "        with open(detailed_path, 'w') as f:\n",
    "            json.dump(detailed_results, f, indent=2)\n",
    "        \n",
    "        # Generate and save report\n",
    "        self._generate_report(summary_df)\n",
    "        \n",
    "        logger.info(f\"Results saved:\")\n",
    "        logger.info(f\"  Summary: {summary_path}\")\n",
    "        logger.info(f\"  Detailed: {detailed_path}\")\n",
    "    \n",
    "    def _generate_report(self, summary_df: pd.DataFrame):\n",
    "        \"\"\"Generate human-readable backtest report.\"\"\"\n",
    "\n",
    "        logger.info(\"üìù Generating human-readable backtest report...\")\n",
    "\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_path = self.output_dir / f\"backtest_report_{timestamp}.txt\"\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"M5 WALMART BACKTESTING REPORT\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Configuration:\\n\")\n",
    "            f.write(f\"  Train start: {self.config.train_start_date}\\n\")\n",
    "            f.write(f\"  Test start: {self.config.test_start_date}\\n\")\n",
    "            f.write(f\"  Test end: {self.config.test_end_date}\\n\")\n",
    "            f.write(f\"  Horizons: {self.config.horizons}\\n\")\n",
    "            f.write(f\"  Models: {self.config.models_to_evaluate}\\n\\n\")\n",
    "            \n",
    "            f.write(\"RESULTS SUMMARY:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            \n",
    "            # Best model by metric\n",
    "            for metric in ['rmse', 'mae', 'mase']:\n",
    "                if metric in summary_df.columns:\n",
    "                    best_idx = summary_df[metric].idxmin()\n",
    "                    best_row = summary_df.iloc[best_idx]\n",
    "                    f.write(f\"Best {metric.upper()}: {best_row['model']} \"\n",
    "                           f\"(H{best_row['horizon']}) = {best_row[metric]:.4f}\\n\")\n",
    "            \n",
    "            f.write(\"\\nDETAILED RESULTS:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            \n",
    "            # Results by model and horizon\n",
    "            for model in summary_df['model'].unique():\n",
    "                f.write(f\"\\n{model.upper()}:\\n\")\n",
    "                model_data = summary_df[summary_df['model'] == model]\n",
    "                for _, row in model_data.iterrows():\n",
    "                    f.write(f\"  H{row['horizon']:2d}: RMSE={row['rmse']:.4f}, \"\n",
    "                           f\"MAE={row['mae']:.4f}, MASE={row['mase']:.4f}, \"\n",
    "                           f\"sMAPE={row['smape']:.2f}%\\n\")\n",
    "        \n",
    "        logger.info(f\"Report saved: {report_path}\")\n",
    "        logger.info(\"‚úÖ Report generation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b84ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(r\"C:\\Users\\Administrator\\OneDrive\\Desktop\\SalesAI\\backend\\data\\features\\m5\\m5_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa75971",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].isnull().sum():\n",
    "        print(f\"{col} contains {df[col].isnull().mean()*100}% null values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3c5c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.580000e+00, 8.260000e+00, 8.380000e+00, 3.970000e+00,\n",
       "       2.970000e+00, 4.340000e+00, 4.640000e+00, 2.980000e+00,\n",
       "       2.480000e+00, 3.080000e+00, 2.880000e+00, 1.000000e+00,\n",
       "       9.600000e-01, 7.940000e+00, 7.880000e+00, 4.600000e-01,\n",
       "       4.200000e-01, 5.000000e-01, 4.800000e-01, 1.560000e+00,\n",
       "       1.770000e+00, 3.170000e+00, 3.480000e+00, 5.980000e+00,\n",
       "       6.270000e+00, 6.520000e+00, 1.970000e+00, 9.800000e-01,\n",
       "       1.160000e+00, 7.000000e-01, 7.200000e-01, 6.800000e-01,\n",
       "       1.880000e+00, 1.980000e+00, 1.188000e+01, 1.067000e+01,\n",
       "       1.098000e+01, 1.168000e+01, 1.268000e+01, 1.177000e+01,\n",
       "       1.197000e+01, 1.147000e+01, 6.860000e+00, 6.980000e+00,\n",
       "       7.180000e+00, 3.440000e+00, 8.980000e+00, 8.560000e+00,\n",
       "       3.740000e+00, 3.980000e+00, 1.797000e+01, 1.300000e+01,\n",
       "       1.998000e+01, 2.077000e+01, 6.670000e+00, 7.980000e+00,\n",
       "       7.440000e+00, 8.000000e-01, 1.085000e+01, 4.700000e-01,\n",
       "       5.400000e-01, 5.800000e-01, 5.700000e-01, 1.597000e+01,\n",
       "       1.686000e+01, 4.660000e+00, 4.780000e+00, 4.860000e+00,\n",
       "       1.590000e+00, 1.780000e+00, 2.120000e+00, 1.120000e+00,\n",
       "       1.297000e+01, 1.348000e+01, 1.244000e+01, 3.220000e+00,\n",
       "       5.880000e+00, 3.400000e+00, 3.530000e+00, 4.220000e+00,\n",
       "       7.480000e+00, 7.830000e+00, 1.510000e+00, 1.480000e+00,\n",
       "       1.058000e+01, 1.898000e+01, 1.872000e+01, 8.680000e+00,\n",
       "       8.280000e+00, 9.840000e+00, 9.400000e-01, 4.480000e+00,\n",
       "       4.880000e+00, 7.970000e+00, 8.670000e+00, 8.820000e+00,\n",
       "       9.470000e+00, 2.997000e+01, 3.098000e+01, 2.996000e+01,\n",
       "       2.760000e+00, 2.830000e+00, 9.700000e-01, 5.220000e+00,\n",
       "       5.470000e+00, 1.232000e+01, 1.250000e+00, 6.840000e+00,\n",
       "       7.240000e+00, 7.000000e+00, 1.248000e+01, 1.368000e+01,\n",
       "       1.323000e+01, 5.160000e+00, 3.670000e+00, 2.940000e+00,\n",
       "       3.430000e+00, 9.780000e+00, 9.980000e+00, 9.860000e+00,\n",
       "       9.460000e+00, 1.228000e+01, 1.278000e+01, 8.440000e+00,\n",
       "       1.472000e+01, 3.780000e+00, 1.738000e+01, 1.748000e+01,\n",
       "       1.592000e+01, 4.380000e+00, 3.940000e+00, 8.620000e+00,\n",
       "       1.288000e+01, 2.570000e+00, 8.400000e-01, 1.080000e+00,\n",
       "       2.280000e+00, 2.380000e+00, 1.988000e+01, 2.038000e+01,\n",
       "       1.996000e+01, 7.680000e+00, 4.300000e+00, 4.240000e+00,\n",
       "       1.426000e+01, 1.568000e+01, 1.497000e+01, 1.488000e+01,\n",
       "       1.548000e+01, 1.398000e+01, 1.000000e+01, 1.148000e+01,\n",
       "       1.128000e+01, 4.980000e+00, 2.398000e+01, 6.440000e+00,\n",
       "       6.680000e+00, 1.212000e+01, 1.198000e+01, 1.298000e+01,\n",
       "       5.960000e+00, 6.120000e+00, 2.840000e+00, 3.120000e+00,\n",
       "       2.920000e+00, 1.680000e+00, 2.680000e+00, 2.720000e+00,\n",
       "       1.470000e+00, 5.970000e+00, 6.470000e+00, 1.062000e+01,\n",
       "       1.112000e+01, 7.790000e+00, 6.970000e+00, 1.173000e+01,\n",
       "       1.220000e+00, 8.170000e+00, 8.770000e+00, 2.640000e+00,\n",
       "       2.730000e+00, 4.580000e+00, 1.224000e+01, 3.380000e+00,\n",
       "       3.560000e+00, 3.870000e+00, 9.920000e+00, 9.500000e+00,\n",
       "       9.480000e+00, 9.830000e+00, 2.630000e+00, 2.460000e+00,\n",
       "       2.740000e+00, 1.280000e+00, 9.970000e+00, 1.094000e+01,\n",
       "       1.420000e+00, 4.420000e+00, 5.500000e+00, 5.360000e+00,\n",
       "       6.180000e+00, 6.380000e+00, 2.500000e+00, 1.100000e+01,\n",
       "       2.298000e+01, 3.240000e+00, 9.420000e+00, 8.960000e+00,\n",
       "       8.970000e+00, 4.970000e+00, 4.830000e+00, 3.230000e+00,\n",
       "       2.820000e+00, 1.097000e+01, 2.000000e+00, 5.480000e+00,\n",
       "       5.670000e+00, 5.940000e+00, 3.000000e+00, 6.870000e+00,\n",
       "       3.320000e+00, 5.000000e+00, 3.340000e+00, 3.420000e+00,\n",
       "       3.540000e+00, 1.247000e+01, 1.284000e+01, 7.470000e+00,\n",
       "       5.780000e+00, 9.720000e+00, 3.140000e+00, 2.530000e+00,\n",
       "       2.620000e+00, 2.780000e+00, 4.720000e+00, 7.500000e+00,\n",
       "       9.000000e+00, 9.670000e+00, 9.880000e+00, 1.068000e+01,\n",
       "       1.052000e+01, 3.470000e+00, 1.740000e+00, 1.930000e+00,\n",
       "       3.000000e-01, 1.000000e-01, 5.770000e+00, 2.178000e+01,\n",
       "       1.994000e+01, 1.388000e+01, 1.688000e+01, 1.583000e+01,\n",
       "       1.367000e+01, 1.676000e+01, 2.580000e+01, 1.073000e+01,\n",
       "       1.178000e+01, 1.320000e+00, 4.470000e+00, 4.250000e+00,\n",
       "       1.088000e+01, 5.760000e+00, 6.580000e+00, 3.280000e+00,\n",
       "       3.680000e+00, 3.880000e+00, 2.000000e-01, 6.370000e+00,\n",
       "       7.380000e+00, 1.528000e+01, 1.270000e+00, 5.620000e+00,\n",
       "       6.240000e+00, 3.660000e+00, 2.870000e+00, 4.820000e+00,\n",
       "       5.120000e+00, 5.720000e+00, 1.466000e+01, 1.798000e+01,\n",
       "       1.230000e+00, 3.570000e+00, 4.670000e+00, 4.280000e+00,\n",
       "       3.960000e+00, 4.270000e+00, 4.870000e+00, 5.240000e+00,\n",
       "       6.280000e+00, 6.960000e+00, 6.420000e+00, 6.720000e+00,\n",
       "       7.780000e+00, 1.196000e+01, 1.500000e+01, 5.320000e+00,\n",
       "       2.770000e+00, 5.580000e+00, 1.342000e+01, 1.448000e+01,\n",
       "       1.372000e+01, 1.450000e+01, 1.494000e+01, 2.790000e+00,\n",
       "       8.500000e-01, 8.880000e+00, 8.370000e+00, 2.240000e+00,\n",
       "       5.680000e+00, 5.860000e+00, 5.990000e+00, 1.138000e+01,\n",
       "       2.797000e+01, 2.896000e+01, 1.940000e+00, 1.070000e+00,\n",
       "       1.140000e+00, 9.340000e+00, 9.940000e+00, 6.000000e-01,\n",
       "       1.340000e+00, 2.080000e+00, 7.220000e+00, 5.430000e+00,\n",
       "       5.570000e+00, 5.740000e+00, 7.920000e+00, 3.620000e+00,\n",
       "       7.280000e+00, 2.470000e+00, 3.770000e+00, 4.740000e+00,\n",
       "       7.370000e+00, 5.300000e-01, 3.370000e+00, 4.770000e+00,\n",
       "       2.300000e-01, 7.700000e-01, 8.800000e-01, 2.580000e+00,\n",
       "       8.700000e-01, 7.400000e-01, 1.670000e+00, 3.500000e+00,\n",
       "       2.500000e-01, 5.000000e-02, 1.500000e+00, 4.000000e+00,\n",
       "       2.670000e+00, 1.570000e+00, 5.460000e+00, 1.170000e+00,\n",
       "       6.320000e+00, 2.370000e+00, 2.360000e+00, 1.072000e+01,\n",
       "       1.540000e+00, 4.630000e+00, 3.360000e+00, 3.920000e+00,\n",
       "       4.940000e+00, 4.500000e+00, 1.047000e+01, 4.840000e+00,\n",
       "       5.640000e+00, 2.660000e+00, 6.480000e+00, 1.086000e+01,\n",
       "       1.048000e+01, 3.930000e+00, 4.230000e+00, 4.960000e+00,\n",
       "       3.840000e+00, 2.960000e+00, 1.547000e+01, 3.860000e+00,\n",
       "       1.660000e+00, 2.297000e+01, 3.070000e+00, 4.180000e+00,\n",
       "       2.260000e+00, 8.480000e+00, 8.470000e+00, 1.578000e+01,\n",
       "       1.667000e+01, 4.620000e+00, 4.930000e+00, 5.270000e+00,\n",
       "       4.140000e+00, 6.770000e+00, 6.880000e+00, 4.540000e+00,\n",
       "       2.320000e+00, 8.330000e+00, 3.260000e+00, 2.860000e+00,\n",
       "       3.640000e+00, 7.670000e+00, 1.520000e+00, 1.870000e+00,\n",
       "       5.890000e+00, 1.460000e+00, 1.060000e+00, 5.920000e+00,\n",
       "       1.186000e+01, 9.300000e-01, 7.930000e+00, 1.193000e+01,\n",
       "       1.960000e+00, 3.990000e+00, 4.260000e+00, 2.420000e+00,\n",
       "       4.920000e+00, 4.680000e+00, 3.820000e+00, 1.720000e+00,\n",
       "       1.380000e+00, 1.830000e+00, 1.257000e+01, 1.640000e+00,\n",
       "       8.870000e+00, 1.152000e+01, 1.044000e+01, 7.420000e+00,\n",
       "       4.460000e+00, 9.740000e+00, 3.760000e+00, 3.720000e+00,\n",
       "       2.270000e+00, 2.990000e+00, 1.990000e+00, 9.870000e+00,\n",
       "       6.940000e+00, 6.530000e+00, 3.460000e+00, 1.860000e+00,\n",
       "       6.640000e+00, 6.990000e+00, 7.860000e+00, 4.170000e+00,\n",
       "       9.680000e+00, 7.270000e+00, 5.440000e+00, 4.570000e+00,\n",
       "       1.490000e+00, 4.130000e+00, 1.887000e+01, 1.896000e+01,\n",
       "       1.258000e+01, 8.940000e+00, 7.120000e+00, 3.730000e+00,\n",
       "       6.560000e+00, 7.330000e+00, 1.000000e-02, 1.572000e+01,\n",
       "       1.546000e+01, 1.242000e+01, 1.227000e+01, 7.520000e+00,\n",
       "       7.560000e+00, 1.840000e+00, 3.580000e+00, 4.440000e+00,\n",
       "       1.730000e+00, 2.053000e+01, 1.696000e+01, 2.490000e+00,\n",
       "       1.598000e+01, 5.730000e+00, 4.990000e+00, 4.430000e+00,\n",
       "       1.620000e+00, 2.220000e+00, 9.960000e+00, 1.043000e+01,\n",
       "       7.870000e+00, 9.430000e+00, 8.430000e+00, 1.158000e+01,\n",
       "       1.184000e+01, 1.027000e+01, 1.077000e+01, 9.270000e+00,\n",
       "       8.270000e+00, 8.640000e+00, 3.270000e+00, 1.920000e+00,\n",
       "       7.960000e+00, 1.083000e+01, 1.997000e+01, 2.094000e+01,\n",
       "       2.097000e+01, 5.340000e+00, 5.840000e+00, 4.490000e+00,\n",
       "       5.820000e+00, 5.280000e+00, 6.460000e+00, 1.394000e+01,\n",
       "       7.430000e+00, 5.750000e+00, 8.000000e+00, 1.440000e+00,\n",
       "       3.330000e+00, 7.540000e+00, 7.500000e-01, 1.213000e+01,\n",
       "       6.540000e+00, 8.860000e+00, 7.460000e+00, 2.000000e+01,\n",
       "       9.930000e+00, 1.240000e+00, 1.324000e+01, 2.560000e+00,\n",
       "       5.870000e+00, 2.140000e+00, 1.427000e+01, 9.260000e+00,\n",
       "       1.096000e+01, 1.167000e+01, 8.240000e+00, 7.800000e-01,\n",
       "       1.127000e+01, 1.294000e+01, 5.080000e+00, 1.246000e+01,\n",
       "       5.461794e+00], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ff0c6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2958084, 82)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c99cbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "item_id                   0\n",
       "dept_id                   0\n",
       "cat_id                    0\n",
       "store_id                  0\n",
       "                         ..\n",
       "sales_ratio_to_7d_avg     0\n",
       "sales_ratio_to_28d_avg    0\n",
       "days_since_first_sale     0\n",
       "zero_sales_flag           0\n",
       "consecutive_zero_days     0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad2e18d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:40:04,177 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mInitialized M5 backtesting engine\u001b[0m\n",
      "[ 2025-09-29 07:40:04,201 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mHorizons: [7, 14, 28]\u001b[0m\n",
      "[ 2025-09-29 07:40:04,203 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mModels: ['lightgbm']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "back = BacktestEngine(BacktestConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e262f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:32:19,194 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müõ†Ô∏è Preparing data for backtesting...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:32:22,443 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Prepared data: 1484376 rows\u001b[0m\n",
      "[ 2025-09-29 07:32:22,469 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müìÖ Date range: 2013-01-01 00:00:00 to 2015-09-01 00:00:00\u001b[0m\n",
      "[ 2025-09-29 07:32:22,582 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müß© Unique series count: 1524\u001b[0m\n",
      "                                id        item_id    dept_id   cat_id  \\\n",
      "703  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "704  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "705  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "706  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "707  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "\n",
      "    store_id state_id      d  sales       date  wm_yr_wk  ...  sales_ewm_14  \\\n",
      "703     CA_1       CA  d_704    0.0 2013-01-01     11249  ...           0.0   \n",
      "704     CA_1       CA  d_705    0.0 2013-01-02     11249  ...           0.0   \n",
      "705     CA_1       CA  d_706    0.0 2013-01-03     11249  ...           0.0   \n",
      "706     CA_1       CA  d_707    0.0 2013-01-04     11249  ...           0.0   \n",
      "707     CA_1       CA  d_708    0.0 2013-01-05     11250  ...           0.0   \n",
      "\n",
      "     sales_ewm_28  time_index  sales_velocity sales_acceleration  \\\n",
      "703           0.0         703             0.0                0.0   \n",
      "704           0.0         704             0.0                0.0   \n",
      "705           0.0         705             0.0                0.0   \n",
      "706           0.0         706             0.0                0.0   \n",
      "707           0.0         707             0.0                0.0   \n",
      "\n",
      "    sales_ratio_to_7d_avg sales_ratio_to_28d_avg days_since_first_sale  \\\n",
      "703                   0.0                    0.0                   704   \n",
      "704                   0.0                    0.0                   705   \n",
      "705                   0.0                    0.0                   706   \n",
      "706                   0.0                    0.0                   707   \n",
      "707                   0.0                    0.0                   708   \n",
      "\n",
      "     zero_sales_flag  consecutive_zero_days  \n",
      "703                1                    -65  \n",
      "704                1                    -64  \n",
      "705                1                    -63  \n",
      "706                1                    -62  \n",
      "707                1                    -61  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "Rows: 1484376, Columns: 82\n",
      "Date range: 2013-01-01 00:00:00 to 2015-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prepared_df = back.prepare_data(df)\n",
    "\n",
    "print(prepared_df.head())\n",
    "print(f\"Rows: {prepared_df.shape[0]}, Columns: {prepared_df.shape[1]}\")\n",
    "print(f\"Date range: {prepared_df['date'].min()} to {prepared_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08774c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:32:22,700 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müîÑ Generating rolling-origin time splits...\u001b[0m\n",
      "[ 2025-09-29 07:32:22,714 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müìä Generated 5 time splits\u001b[0m\n",
      "Generated 5 splits\n",
      "('2015-03-02', '2015-05-31', '2015-06-01')\n",
      "('2015-03-22', '2015-06-20', '2015-06-21')\n",
      "('2015-04-11', '2015-07-10', '2015-07-11')\n"
     ]
    }
   ],
   "source": [
    "time_splits = back.get_time_splits()\n",
    "print(f\"Generated {len(time_splits)} splits\")\n",
    "\n",
    "for split in time_splits[:3]:  # show first 3 splits\n",
    "    print(split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89f08df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LightGBMModel'>\n"
     ]
    }
   ],
   "source": [
    "model = back.create_model('lightgbm')\n",
    "print(type(model)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54fcac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:32:22,784 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mEvaluating split: train 2015-03-02 to 2015-05-31, test from 2015-06-01\u001b[0m\n",
      "[ 2025-09-29 07:32:22,914 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mTraining lightgbm...\u001b[0m\n",
      "[ 2025-09-29 07:32:22,941 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müöÄ Starting LightGBM training...\u001b[0m\n",
      "[ 2025-09-29 07:32:38,786 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müìä Feature importance computed for 76 features\u001b[0m\n",
      "[ 2025-09-29 07:32:38,787 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Training completed in 15.84 seconds\u001b[0m\n",
      "[ 2025-09-29 07:32:38,820 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚ö° Starting prediction...\u001b[0m\n",
      "[ 2025-09-29 07:32:39,049 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Prediction completed in 0.23 seconds\u001b[0m\n",
      "[ 2025-09-29 07:32:39,051 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müöÄ Calculating all evaluation metrics...\u001b[0m\n",
      "[ 2025-09-29 07:32:39,095 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Metrics calculated: RMSE=0.1001, MAE=0.0106, MASE=0.0103, SMAPE=120.46%, MAPE=0.35%\u001b[0m\n",
      "[ 2025-09-29 07:32:39,107 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mlightgbm H7: RMSE=0.100, MAE=0.011, MASE=0.010\u001b[0m\n",
      "[ 2025-09-29 07:32:39,163 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚ö° Starting prediction...\u001b[0m\n",
      "[ 2025-09-29 07:32:39,606 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Prediction completed in 0.44 seconds\u001b[0m\n",
      "[ 2025-09-29 07:32:39,609 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müöÄ Calculating all evaluation metrics...\u001b[0m\n",
      "[ 2025-09-29 07:32:39,621 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Metrics calculated: RMSE=0.0917, MAE=0.0101, MASE=0.0098, SMAPE=122.29%, MAPE=0.34%\u001b[0m\n",
      "[ 2025-09-29 07:32:39,629 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mlightgbm H14: RMSE=0.092, MAE=0.010, MASE=0.010\u001b[0m\n",
      "[ 2025-09-29 07:32:39,729 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚ö° Starting prediction...\u001b[0m\n",
      "[ 2025-09-29 07:32:40,538 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Prediction completed in 0.81 seconds\u001b[0m\n",
      "[ 2025-09-29 07:32:40,540 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müöÄ Calculating all evaluation metrics...\u001b[0m\n",
      "[ 2025-09-29 07:32:40,551 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Metrics calculated: RMSE=0.0977, MAE=0.0104, MASE=0.0101, SMAPE=121.81%, MAPE=0.34%\u001b[0m\n",
      "[ 2025-09-29 07:32:40,557 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mlightgbm H28: RMSE=0.098, MAE=0.010, MASE=0.010\u001b[0m\n",
      "Number of results: 3\n",
      "Model: lightgbm, Horizon: 7, RMSE: 0.100\n",
      "Model: lightgbm, Horizon: 14, RMSE: 0.092\n",
      "Model: lightgbm, Horizon: 28, RMSE: 0.098\n"
     ]
    }
   ],
   "source": [
    "train_start, train_end, test_start = time_splits[0]  # first split\n",
    "\n",
    "# Use the prepared dataframe from step 1\n",
    "split_results = back.evaluate_split(prepared_df, train_start, train_end, test_start)\n",
    "\n",
    "print(f\"Number of results: {len(split_results)}\")\n",
    "for res in split_results:\n",
    "    print(f\"Model: {res.model_name}, Horizon: {res.horizon}, RMSE: {res.metrics.rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd9f3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []\n",
    "all_result.extend(split_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6c019f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:35:50,515 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müìä Aggregating backtest results...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_df = back._aggregate_results(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87991f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>horizon</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mase</th>\n",
       "      <th>smape</th>\n",
       "      <th>training_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>n_splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100085</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>120.462562</td>\n",
       "      <td>15.844203</td>\n",
       "      <td>0.227137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>14</td>\n",
       "      <td>0.091731</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>122.292200</td>\n",
       "      <td>15.844203</td>\n",
       "      <td>0.441079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>28</td>\n",
       "      <td>0.097708</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>121.810299</td>\n",
       "      <td>15.844203</td>\n",
       "      <td>0.806957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  horizon      rmse       mae      mase       smape  training_time  \\\n",
       "0  lightgbm        7  0.100085  0.010579  0.010268  120.462562      15.844203   \n",
       "1  lightgbm       14  0.091731  0.010094  0.009797  122.292200      15.844203   \n",
       "2  lightgbm       28  0.097708  0.010386  0.010081  121.810299      15.844203   \n",
       "\n",
       "   prediction_time  n_splits  \n",
       "0         0.227137         1  \n",
       "1         0.441079         1  \n",
       "2         0.806957         1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8a526b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:40:08,660 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müíæ Saving final backtest results and generating report...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-09-29 07:40:08,740 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32müìù Generating human-readable backtest report...\u001b[0m\n",
      "[ 2025-09-29 07:40:08,797 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mReport saved: backtest_results\\backtest_report_20250929_074008.txt\u001b[0m\n",
      "[ 2025-09-29 07:40:08,801 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m‚úÖ Report generation completed.\u001b[0m\n",
      "[ 2025-09-29 07:40:08,804 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32mResults saved:\u001b[0m\n",
      "[ 2025-09-29 07:40:08,809 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m  Summary: backtest_results\\backtest_summary_20250929_074008.csv\u001b[0m\n",
      "[ 2025-09-29 07:40:08,815 ] __main__ - \u001b[32mINFO\u001b[0m - \u001b[32m  Detailed: backtest_results\\backtest_detailed_20250929_074008.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "back._save_final_results(results_df,all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b30db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
